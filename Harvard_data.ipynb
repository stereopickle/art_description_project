{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "Here I will take the open source object data from Harvard Museum.  \n",
    "(API Documentation and data source: https://www.harvardartmuseums.org/collections/api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must request the API key from Harvard Museum by using a link provided in their documentations.  \n",
    "Usually you will receive the key right away.  \n",
    "Then create a harvard_mus_api.json file to store the key as a dictionary.  \n",
    "e.g. {\"api_key\": \"your key here\"}  \n",
    "If you are not uploading this to public and it's for your personal use, you can ignore below step and just assign api_key to your api key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(path):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "path = '/Users/stereopickles/.secret' # input the location of your tmdb_api.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = get_keys(f\"{path}/harvard_mus_api.json\")['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.harvardartmuseums.org/object\"\n",
    "\n",
    "url_params = {\n",
    "    \"apikey\": api_key,\n",
    "}\n",
    "\n",
    "resp = requests.get(url, params = url_params)\n",
    "print(resp.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'records'])\n"
     ]
    }
   ],
   "source": [
    "print(resp.json().keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalrecordsperquery': 10,\n",
       " 'totalrecords': 234997,\n",
       " 'pages': 23500,\n",
       " 'page': 1,\n",
       " 'next': 'https://api.harvardartmuseums.org/object?apikey=def72120-c45a-11ea-89a3-6722767e4145&page=2'}"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()['info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep it to paintings only for the first round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Paintings'] \n",
    "full_db = []\n",
    "\n",
    "for cls in classes: \n",
    "    url_params = {\n",
    "        \"apikey\": api_key, \n",
    "        \"classification\": cls, \n",
    "    }\n",
    "    \n",
    "    res = requests.get(url, params = url_params)\n",
    "    \n",
    "    if res.status_code == 200: # if connection is successful\n",
    "        # run the rest of the pages\n",
    "        n = int(res.json()['info']['pages']) # getting the page number \n",
    "        \n",
    "        for i in range(n):\n",
    "            url_params = {\n",
    "                \"apikey\": api_key,\n",
    "                \"classification\": cls, \n",
    "                \"page\": i\n",
    "            }\n",
    "\n",
    "            resp = requests.get(url, params = url_params)\n",
    "            \n",
    "            try: \n",
    "                full_db.extend(resp.json()['records']) # add it to the list\n",
    "            except:\n",
    "                print(f\"Error on page {i+1}\") # let me know if there's an error\n",
    "\n",
    "    else: \n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to a Pandas dataframe\n",
    "full_df = pd.DataFrame(full_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop items without tags\n",
    "full_df.dropna(subset = [\"description\"], inplace = True)\n",
    "full_df.description.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paintings    557\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will preprocess the description data.  \n",
    "We will do  \n",
    "1. Make everything lowercase \n",
    "2. Remove stopwords\n",
    "3. Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = full_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will remove all the stopwords using stopwords corpus from NLTK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK stemming/lemmatizing options\n",
    "I'll quickly run through porter stemmer, lancaster stemmer and worldnetlemmatizer to choose the best option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = ['abstract', 'abstracts', 'abstracted', \n",
    "            'abstracting', 'abstraction', 'women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancaster Stemmer: \n",
      "['abstract', 'abstract', 'abstract', 'abstract', 'abstract', 'wom']\n",
      "Porter Stemmer: \n",
      "['abstract', 'abstract', 'abstract', 'abstract', 'abstract', 'women']\n",
      "Worldnet Lemmatizer: \n",
      "['abstract', 'abstract', 'abstracted', 'abstracting', 'abstraction', 'woman']\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "print(\"Lancaster Stemmer: \")\n",
    "print([lancaster.stem(x) for x in testlist])\n",
    "print(\"Porter Stemmer: \")\n",
    "print([porter.stem(x) for x in testlist])\n",
    "print(\"Worldnet Lemmatizer: \")\n",
    "print([wnl.lemmatize(x) for x in testlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like best way might be to run Porter Stemmer first and then running Worldnet Lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalizing(string):\n",
    "    \"\"\"\n",
    "    Input: string \n",
    "    Return: list of lower case keywords with special characters removed\n",
    "\n",
    "    \"\"\"\n",
    "    # remove special character, lowercase, then remove individual words\n",
    "    return re.sub('[^A-Za-z]+', ' ', string).lower().split() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words corpus\n",
    "# We'll take from NLTK package and add couple more\n",
    "sw = stopwords.words('english')\n",
    "sw += ['p', 'r', 'l', 'x', 'e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(list_):\n",
    "    \"\"\"\n",
    "    Input: list of words\n",
    "    Return: list of words excluding stopwords\n",
    "    \"\"\"\n",
    "    return [x for x in list_ if x not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_keywords(string):\n",
    "    \"\"\"\n",
    "    Input: string of words\n",
    "    Return: list of words excluding stopwords (after normalizing) and lemmatized\n",
    "    \"\"\"\n",
    "    wordslist = remove_stop(normalizing(string))\n",
    "    return list(map(lambda x: wnl.lemmatize(porter.stem(x)), wordslist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.description = clean_df.description.apply(lambda x: make_keywords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking\n",
    "Let's just randomly checks couple samples to ensure it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3147    [vasakasajja, nayika, heroin, dress, lover, paint, shown, open, terrac, seat, surround, femal, attend, one, help, shoe, distanc, left, lover, seen, seat, dayb, smoke, hookah, pahari, style, kangra, school]\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "clean_df.sample(1).description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vasakasajja nayika, is a heroine who dresses up for her lover. Here, in this painting, she is shown on an open terrace, seated and surrounded by female attendants, one of whom helps her with her shoes. In the distance, on the left, her lover can be seen seated on a daybed and smoking a hookah. Pahari Style, Kangra School.\n"
     ]
    }
   ],
   "source": [
    "print(full_df.loc[3147, 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sum(clean_df.description, [])\n",
    "unique = set(words)\n",
    "counts = dict.fromkeys(unique, 0)\n",
    "for w in words: \n",
    "    counts[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts = {k: v for k, v in sorted(counts.items(), reverse = True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paint': 608,\n",
       " 'right': 266,\n",
       " 'left': 241,\n",
       " 'artist': 193,\n",
       " 'white': 193,\n",
       " 'depict': 178,\n",
       " 'two': 169,\n",
       " 'figur': 158,\n",
       " 'larg': 154,\n",
       " 'wear': 154,\n",
       " 'red': 148,\n",
       " 'one': 146,\n",
       " 'ink': 142,\n",
       " 'appear': 141,\n",
       " 'composit': 141,\n",
       " 'gold': 134,\n",
       " 'landscap': 134,\n",
       " 'style': 133,\n",
       " 'hold': 127,\n",
       " 'hand': 123,\n",
       " 'chine': 122,\n",
       " 'portrait': 120,\n",
       " 'scroll': 119,\n",
       " 'tree': 104,\n",
       " 'top': 101,\n",
       " 'work': 100,\n",
       " 'flower': 98,\n",
       " 'head': 97,\n",
       " 'black': 94,\n",
       " 'blue': 94,\n",
       " 'krishna': 90,\n",
       " 'paper': 90,\n",
       " 'mountain': 88,\n",
       " 'green': 88,\n",
       " 'attend': 83,\n",
       " 'small': 83,\n",
       " 'color': 83,\n",
       " 'school': 82,\n",
       " 'long': 82,\n",
       " 'god': 81,\n",
       " 'origin': 80,\n",
       " 'charact': 80,\n",
       " 'femal': 78,\n",
       " 'stand': 78,\n",
       " 'also': 78,\n",
       " 'background': 75,\n",
       " 'hindu': 73,\n",
       " 'set': 73,\n",
       " 'screen': 73,\n",
       " 'inscript': 73,\n",
       " 'seal': 72,\n",
       " 'center': 70,\n",
       " 'face': 70,\n",
       " 'side': 69,\n",
       " 'mao': 69,\n",
       " 'decor': 69,\n",
       " 'panel': 69,\n",
       " 'centuri': 67,\n",
       " 'repres': 65,\n",
       " 'lower': 64,\n",
       " 'use': 63,\n",
       " 'hang': 61,\n",
       " 'scene': 60,\n",
       " 'behind': 60,\n",
       " 'leav': 59,\n",
       " 'front': 58,\n",
       " 'three': 58,\n",
       " 'dark': 58,\n",
       " 'rajput': 58,\n",
       " 'around': 57,\n",
       " 'turban': 57,\n",
       " 'like': 57,\n",
       " 'featur': 56,\n",
       " 'mount': 56,\n",
       " 'corner': 55,\n",
       " 'art': 55,\n",
       " 'robe': 54,\n",
       " 'sit': 53,\n",
       " 'painter': 53,\n",
       " 'seat': 53,\n",
       " 'rock': 52,\n",
       " 'edg': 52,\n",
       " 'vishnu': 51,\n",
       " 'ear': 50,\n",
       " 'water': 50,\n",
       " 'orang': 49,\n",
       " 'four': 49,\n",
       " 'creat': 48,\n",
       " 'tradit': 47,\n",
       " 'woman': 47,\n",
       " 'border': 47,\n",
       " 'cover': 47,\n",
       " 'foreground': 46,\n",
       " 'read': 45,\n",
       " 'carri': 45,\n",
       " 'signatur': 45,\n",
       " 'king': 45,\n",
       " 'back': 44,\n",
       " 'leaf': 44,\n",
       " 'frame': 43,\n",
       " 'includ': 43,\n",
       " 'lotu': 43,\n",
       " 'form': 43,\n",
       " 'male': 42,\n",
       " 'squar': 42,\n",
       " 'group': 41,\n",
       " 'base': 41,\n",
       " 'pair': 41,\n",
       " 'suggest': 40,\n",
       " 'pink': 40,\n",
       " 'surround': 40,\n",
       " 'bird': 40,\n",
       " 'ground': 39,\n",
       " 'deiti': 39,\n",
       " 'view': 39,\n",
       " 'brown': 39,\n",
       " 'museum': 39,\n",
       " 'bottom': 39,\n",
       " 'type': 39,\n",
       " 'upper': 39,\n",
       " 'korean': 38,\n",
       " 'known': 38,\n",
       " 'area': 38,\n",
       " 'branch': 38,\n",
       " 'princ': 38,\n",
       " 'leg': 38,\n",
       " 'dress': 37,\n",
       " 'shoulder': 37,\n",
       " 'bamboo': 37,\n",
       " 'china': 37,\n",
       " 'arm': 37,\n",
       " 'new': 37,\n",
       " 'hair': 37,\n",
       " 'avatar': 36,\n",
       " 'well': 36,\n",
       " 'scholar': 36,\n",
       " 'blossom': 36,\n",
       " 'imag': 35,\n",
       " 'hors': 35,\n",
       " 'gray': 35,\n",
       " 'play': 35,\n",
       " 'yellow': 34,\n",
       " 'ornament': 34,\n",
       " 'wash': 34,\n",
       " 'plum': 34,\n",
       " 'peak': 34,\n",
       " 'foot': 34,\n",
       " 'cloud': 33,\n",
       " 'pearl': 33,\n",
       " 'copi': 33,\n",
       " 'present': 33,\n",
       " 'year': 33,\n",
       " 'late': 33,\n",
       " 'eighth': 33,\n",
       " 'end': 32,\n",
       " 'bodi': 32,\n",
       " 'fan': 32,\n",
       " 'bracelet': 31,\n",
       " 'symbol': 31,\n",
       " 'sky': 31,\n",
       " 'necklac': 31,\n",
       " 'written': 31,\n",
       " 'first': 31,\n",
       " 'young': 31,\n",
       " 'sever': 31,\n",
       " 'album': 31,\n",
       " 'sash': 31,\n",
       " 'viewer': 31,\n",
       " 'rest': 31,\n",
       " 'river': 30,\n",
       " 'dynasti': 30,\n",
       " 'music': 30,\n",
       " 'date': 30,\n",
       " 'genji': 30,\n",
       " 'period': 30,\n",
       " 'lover': 30,\n",
       " 'anoth': 30,\n",
       " 'line': 30,\n",
       " 'inscrib': 30,\n",
       " 'vertic': 30,\n",
       " 'pictori': 29,\n",
       " 'execut': 29,\n",
       " 'shown': 29,\n",
       " 'ring': 29,\n",
       " 'follow': 29,\n",
       " 'brush': 29,\n",
       " 'worship': 29,\n",
       " 'terrac': 29,\n",
       " 'render': 29,\n",
       " 'royal': 29,\n",
       " 'singh': 28,\n",
       " 'accompani': 28,\n",
       " 'although': 28,\n",
       " 'japanes': 28,\n",
       " 'statu': 28,\n",
       " 'moon': 28,\n",
       " 'buddhist': 27,\n",
       " 'orchid': 27,\n",
       " 'within': 27,\n",
       " 'central': 27,\n",
       " 'fabric': 27,\n",
       " 'may': 27,\n",
       " 'rise': 27,\n",
       " 'pahari': 27,\n",
       " 'flank': 27,\n",
       " 'waist': 27,\n",
       " 'state': 27,\n",
       " 'exhibit': 27,\n",
       " 'pavilion': 27,\n",
       " 'raga': 26,\n",
       " 'mist': 26,\n",
       " 'beard': 26,\n",
       " 'chairman': 26,\n",
       " 'silk': 26,\n",
       " 'univers': 26,\n",
       " 'skin': 26,\n",
       " 'subject': 26,\n",
       " 'collect': 26,\n",
       " 'bear': 26,\n",
       " 'space': 26,\n",
       " 'wall': 26,\n",
       " 'thu': 26,\n",
       " 'calligraph': 25,\n",
       " 'identifi': 25,\n",
       " 'show': 25,\n",
       " 'shiva': 25,\n",
       " 'old': 25,\n",
       " 'surfac': 25,\n",
       " 'earli': 25,\n",
       " 'musician': 25,\n",
       " 'brushwork': 25,\n",
       " 'indic': 25,\n",
       " 'text': 25,\n",
       " 'open': 25,\n",
       " 'wang': 24,\n",
       " 'consist': 24,\n",
       " 'pigment': 24,\n",
       " 'heroin': 24,\n",
       " 'offici': 24,\n",
       " 'among': 24,\n",
       " 'commonli': 23,\n",
       " 'would': 23,\n",
       " 'refer': 23,\n",
       " 'beij': 23,\n",
       " 'halo': 23,\n",
       " 'ming': 23,\n",
       " 'made': 23,\n",
       " 'either': 23,\n",
       " 'point': 23,\n",
       " 'mughal': 23,\n",
       " 'eye': 23,\n",
       " 'howev': 23,\n",
       " 'shape': 23,\n",
       " 'column': 23,\n",
       " 'jewelri': 23,\n",
       " 'skirt': 23,\n",
       " 'nayika': 23,\n",
       " 'garden': 23,\n",
       " 'dot': 23,\n",
       " 'popular': 22,\n",
       " 'portion': 22,\n",
       " 'light': 22,\n",
       " 'full': 22,\n",
       " 'fold': 22,\n",
       " 'distanc': 22,\n",
       " 'seen': 22,\n",
       " 'hunt': 22,\n",
       " 'monk': 22,\n",
       " 'crown': 22,\n",
       " 'middl': 22,\n",
       " 'sword': 22,\n",
       " 'finish': 22,\n",
       " 'separ': 22,\n",
       " 'poem': 22,\n",
       " 'cross': 22,\n",
       " 'across': 22,\n",
       " 'near': 22,\n",
       " 'neck': 22,\n",
       " 'valley': 22,\n",
       " 'script': 22,\n",
       " 'part': 22,\n",
       " 'toward': 22,\n",
       " 'armlet': 22,\n",
       " 'deer': 21,\n",
       " 'time': 21,\n",
       " 'palac': 21,\n",
       " 'song': 21,\n",
       " 'pattern': 21,\n",
       " 'look': 21,\n",
       " 'adorn': 21,\n",
       " 'n': 21,\n",
       " 'individu': 21,\n",
       " 'run': 21,\n",
       " 'hong': 21,\n",
       " 'see': 21,\n",
       " 'shrine': 21,\n",
       " 'ragini': 21,\n",
       " 'nineteenth': 21,\n",
       " 'calligraphi': 21,\n",
       " 'onto': 21,\n",
       " 'plant': 20,\n",
       " 'partial': 20,\n",
       " 'mani': 20,\n",
       " 'build': 20,\n",
       " 'fire': 20,\n",
       " 'compris': 20,\n",
       " 'master': 20,\n",
       " 'tall': 20,\n",
       " 'korea': 20,\n",
       " 'translat': 20,\n",
       " 'grow': 20,\n",
       " 'c': 20,\n",
       " 'far': 20,\n",
       " 'distant': 20,\n",
       " 'layer': 20,\n",
       " 'mt': 20,\n",
       " 'eight': 20,\n",
       " 'jama': 20,\n",
       " 'radha': 19,\n",
       " 'eleph': 19,\n",
       " 'emperor': 19,\n",
       " 'along': 19,\n",
       " 'minoan': 19,\n",
       " 'ruler': 19,\n",
       " 'posit': 19,\n",
       " 'variou': 19,\n",
       " 'appli': 19,\n",
       " 'scarf': 19,\n",
       " 'member': 19,\n",
       " 'canva': 19,\n",
       " 'six': 19,\n",
       " 'famou': 19,\n",
       " 'rectangular': 19,\n",
       " 'phrase': 19,\n",
       " 'studi': 19,\n",
       " 'pine': 19,\n",
       " 'famili': 19,\n",
       " 'approach': 19,\n",
       " 'trim': 19,\n",
       " 'perch': 19,\n",
       " 'h': 19,\n",
       " 'emei': 18,\n",
       " 'disc': 18,\n",
       " 'pu': 18,\n",
       " 'nose': 18,\n",
       " 'visibl': 18,\n",
       " 'fli': 18,\n",
       " 'anim': 18,\n",
       " 'detail': 18,\n",
       " 'impress': 18,\n",
       " 'design': 18,\n",
       " 'lead': 18,\n",
       " 'format': 18,\n",
       " 'taiwan': 18,\n",
       " 'rais': 18,\n",
       " 'basi': 18,\n",
       " 'offer': 18,\n",
       " 'abstract': 18,\n",
       " 'instrument': 18,\n",
       " 'yet': 18,\n",
       " 'delic': 17,\n",
       " 'distinct': 17,\n",
       " 'ten': 17,\n",
       " 'kota': 17,\n",
       " 'brushstrok': 17,\n",
       " 'orient': 17,\n",
       " 'arrang': 17,\n",
       " 'textur': 17,\n",
       " 'call': 17,\n",
       " 'typic': 17,\n",
       " 'pale': 17,\n",
       " 'harvard': 17,\n",
       " 'structur': 17,\n",
       " 'cho': 17,\n",
       " 'reflect': 17,\n",
       " 'stalk': 17,\n",
       " 'even': 17,\n",
       " 'contain': 17,\n",
       " 'nation': 17,\n",
       " 'fill': 17,\n",
       " 'shirt': 17,\n",
       " 'hous': 17,\n",
       " 'literati': 17,\n",
       " 'kim': 17,\n",
       " 'japan': 16,\n",
       " 'elabor': 16,\n",
       " 'done': 16,\n",
       " 'order': 16,\n",
       " 'thick': 16,\n",
       " 'techniqu': 16,\n",
       " 'probabl': 16,\n",
       " 'bodhisattva': 16,\n",
       " 'string': 16,\n",
       " 'kong': 16,\n",
       " 'togeth': 16,\n",
       " 'shawl': 16,\n",
       " 'improvis': 16,\n",
       " 'metaphor': 16,\n",
       " 'transluc': 16,\n",
       " 'titl': 16,\n",
       " 'peacock': 16,\n",
       " 'consort': 16,\n",
       " 'yi': 16,\n",
       " 'waterfal': 16,\n",
       " 'purpl': 16,\n",
       " 'western': 16,\n",
       " 'addit': 16,\n",
       " 'plain': 16,\n",
       " 'blank': 15,\n",
       " 'thin': 15,\n",
       " 'deep': 15,\n",
       " 'sign': 15,\n",
       " 'man': 15,\n",
       " 'accord': 15,\n",
       " 'seem': 15,\n",
       " 'atop': 15,\n",
       " 'cluster': 15,\n",
       " 'vari': 15,\n",
       " 'downward': 15,\n",
       " 'snow': 15,\n",
       " 'kangra': 15,\n",
       " 'roof': 15,\n",
       " 'chijang': 15,\n",
       " 'next': 15,\n",
       " 'posal': 15,\n",
       " 'last': 15,\n",
       " 'profil': 15,\n",
       " 'tie': 15,\n",
       " 'perhap': 15,\n",
       " 'reveal': 15,\n",
       " 'way': 15,\n",
       " 'occupi': 15,\n",
       " 'proper': 15,\n",
       " 'mean': 15,\n",
       " 'seri': 15,\n",
       " 'trunk': 15,\n",
       " 'distinguish': 15,\n",
       " 'singl': 15,\n",
       " 'mirror': 15,\n",
       " 'insid': 14,\n",
       " 'imageri': 14,\n",
       " 'gaze': 14,\n",
       " 'still': 14,\n",
       " 'obscur': 14,\n",
       " 'attribut': 14,\n",
       " 'collar': 14,\n",
       " 'person': 14,\n",
       " 'live': 14,\n",
       " 'oil': 14,\n",
       " 'grid': 14,\n",
       " 'unfinish': 14,\n",
       " 'version': 14,\n",
       " 'slightli': 14,\n",
       " 'life': 14,\n",
       " 'denot': 14,\n",
       " 'draw': 14,\n",
       " 'gener': 14,\n",
       " 'dong': 14,\n",
       " 'reced': 14,\n",
       " 'strip': 14,\n",
       " 'lion': 14,\n",
       " 'brother': 14,\n",
       " 'unembellish': 14,\n",
       " 'liu': 14,\n",
       " 'beauti': 14,\n",
       " 'circular': 14,\n",
       " 'trouser': 14,\n",
       " 'men': 14,\n",
       " 'becam': 14,\n",
       " 'garment': 14,\n",
       " 'associ': 14,\n",
       " 'cloth': 14,\n",
       " 'complet': 14,\n",
       " 'element': 14,\n",
       " 'roll': 14,\n",
       " 'court': 14,\n",
       " 'away': 14,\n",
       " 'wide': 14,\n",
       " 'continu': 14,\n",
       " 'falcon': 13,\n",
       " 'turn': 13,\n",
       " 'evok': 13,\n",
       " 'natur': 13,\n",
       " 'cursiv': 13,\n",
       " 'serv': 13,\n",
       " 'door': 13,\n",
       " 'wife': 13,\n",
       " 'hill': 13,\n",
       " 'love': 13,\n",
       " 'throne': 13,\n",
       " 'mewar': 13,\n",
       " 'upward': 13,\n",
       " 'jacket': 13,\n",
       " 'mustach': 13,\n",
       " 'describ': 13,\n",
       " 'triptych': 13,\n",
       " 'great': 13,\n",
       " 'world': 13,\n",
       " 'classic': 13,\n",
       " 'provinc': 13,\n",
       " 'chair': 13,\n",
       " 'wrap': 13,\n",
       " 'rang': 13,\n",
       " 'convers': 13,\n",
       " 'move': 13,\n",
       " 'rather': 13,\n",
       " 'reach': 13,\n",
       " 'past': 13,\n",
       " 'fruit': 13,\n",
       " 'intend': 13,\n",
       " 'receiv': 13,\n",
       " 'splash': 13,\n",
       " 'second': 13,\n",
       " 'page': 13,\n",
       " 'ch': 13,\n",
       " 'whisk': 13,\n",
       " 'relief': 13,\n",
       " 'bright': 13,\n",
       " 'extend': 13,\n",
       " 'lush': 13,\n",
       " 'child': 13,\n",
       " 'domin': 13,\n",
       " 'maharaja': 13,\n",
       " 'th': 13,\n",
       " 'gentleman': 13,\n",
       " 'larger': 13,\n",
       " 'indian': 13,\n",
       " 'compani': 13,\n",
       " 'though': 13,\n",
       " 'grass': 13,\n",
       " 'horizont': 12,\n",
       " 'develop': 12,\n",
       " 'enjoy': 12,\n",
       " 'priest': 12,\n",
       " 'beneath': 12,\n",
       " 'golden': 12,\n",
       " 'dy': 12,\n",
       " 'icon': 12,\n",
       " 'ng': 12,\n",
       " 'watercolor': 12,\n",
       " 'process': 12,\n",
       " 'tuck': 12,\n",
       " 'emerg': 12,\n",
       " 'fall': 12,\n",
       " 'third': 12,\n",
       " 'activ': 12,\n",
       " 'begin': 12,\n",
       " 'own': 12,\n",
       " 'take': 12,\n",
       " 'ascet': 12,\n",
       " 'almost': 12,\n",
       " 'snake': 12,\n",
       " 'window': 12,\n",
       " 'rama': 12,\n",
       " 'mouth': 12,\n",
       " 'heron': 12,\n",
       " 'half': 12,\n",
       " 'direct': 12,\n",
       " 'cow': 12,\n",
       " 'fine': 12,\n",
       " 'fact': 12,\n",
       " 'rug': 12,\n",
       " 'cousin': 12,\n",
       " 'stroke': 12,\n",
       " 'object': 12,\n",
       " 'qing': 12,\n",
       " 'chest': 12,\n",
       " 'gestur': 12,\n",
       " 'simpl': 12,\n",
       " 'remain': 12,\n",
       " 'kneel': 12,\n",
       " 'galleri': 12,\n",
       " 'spring': 12,\n",
       " 'morn': 11,\n",
       " 'curv': 11,\n",
       " 'short': 11,\n",
       " 'tower': 11,\n",
       " 'section': 11,\n",
       " 'worn': 11,\n",
       " 'st': 11,\n",
       " 'arrow': 11,\n",
       " 'lake': 11,\n",
       " 'main': 11,\n",
       " 'intaglio': 11,\n",
       " 'come': 11,\n",
       " 'confucian': 11,\n",
       " 'rever': 11,\n",
       " 'skill': 11,\n",
       " 'came': 11,\n",
       " 'row': 11,\n",
       " 'held': 11,\n",
       " 'pond': 11,\n",
       " 'wind': 11,\n",
       " 'anklet': 11,\n",
       " 'buddha': 11,\n",
       " 'k': 11,\n",
       " 'strand': 11,\n",
       " 'forest': 11,\n",
       " 'standard': 11,\n",
       " 'train': 11,\n",
       " 'room': 11,\n",
       " 'cushion': 11,\n",
       " 'shishupala': 11,\n",
       " 'drape': 11,\n",
       " 'place': 11,\n",
       " 'autumn': 11,\n",
       " 'bud': 11,\n",
       " 'war': 11,\n",
       " 'henna': 11,\n",
       " 'li': 11,\n",
       " 'narrow': 11,\n",
       " 'born': 11,\n",
       " 'trace': 11,\n",
       " 'thatch': 11,\n",
       " 'sun': 11,\n",
       " 'hillock': 11,\n",
       " 'sketch': 11,\n",
       " 'contrast': 11,\n",
       " 'silver': 11,\n",
       " 'eighteenth': 11,\n",
       " 'enclos': 11,\n",
       " 'danc': 10,\n",
       " 'broad': 10,\n",
       " 'other': 10,\n",
       " 'modern': 10,\n",
       " 'without': 10,\n",
       " 'outdoor': 10,\n",
       " 'found': 10,\n",
       " 'sleev': 10,\n",
       " 'becom': 10,\n",
       " 'game': 10,\n",
       " 'sita': 10,\n",
       " 'ask': 10,\n",
       " 'ru': 10,\n",
       " 'immedi': 10,\n",
       " 'bare': 10,\n",
       " 'five': 10,\n",
       " 'damag': 10,\n",
       " 'histori': 10,\n",
       " 'emerald': 10,\n",
       " 'ox': 10,\n",
       " 'stripe': 10,\n",
       " 'underneath': 10,\n",
       " 'embellish': 10,\n",
       " 'preserv': 10,\n",
       " 'upon': 10,\n",
       " 'locat': 10,\n",
       " 'might': 10,\n",
       " 'express': 10,\n",
       " 'crop': 10,\n",
       " 'photograph': 10,\n",
       " 'word': 10,\n",
       " 'prepar': 10,\n",
       " 'raja': 10,\n",
       " 'boat': 10,\n",
       " 'fifth': 10,\n",
       " 'nativ': 10,\n",
       " 'differ': 10,\n",
       " 'entir': 10,\n",
       " 'import': 10,\n",
       " 'hat': 10,\n",
       " 'believ': 10,\n",
       " 'cottag': 10,\n",
       " 'exist': 10,\n",
       " 'number': 10,\n",
       " 'forc': 10,\n",
       " 'yashoda': 10,\n",
       " 'tunic': 10,\n",
       " 'dagger': 10,\n",
       " 'winter': 10,\n",
       " 'patka': 10,\n",
       " 'professor': 10,\n",
       " 'john': 10,\n",
       " 'bead': 10,\n",
       " 'length': 10,\n",
       " 'flow': 10,\n",
       " 'villag': 10,\n",
       " 'shah': 10,\n",
       " 'promin': 10,\n",
       " 'fragment': 10,\n",
       " 'compos': 10,\n",
       " 'relat': 10,\n",
       " 'mid': 10,\n",
       " 'otherwis': 10,\n",
       " 'combin': 10,\n",
       " 'began': 10,\n",
       " 'york': 10,\n",
       " 'signifi': 10,\n",
       " 'verso': 10,\n",
       " 'night': 10,\n",
       " 'return': 10,\n",
       " 'zhang': 10,\n",
       " 'spread': 9,\n",
       " 'mat': 9,\n",
       " 'sobriquet': 9,\n",
       " 'curl': 9,\n",
       " 'dome': 9,\n",
       " 'tone': 9,\n",
       " 'academi': 9,\n",
       " 'drawn': 9,\n",
       " 'cut': 9,\n",
       " 'khan': 9,\n",
       " 'akbar': 9,\n",
       " 'plane': 9,\n",
       " 'dri': 9,\n",
       " 'piec': 9,\n",
       " 'vener': 9,\n",
       " 'band': 9,\n",
       " 'store': 9,\n",
       " 'mass': 9,\n",
       " 'collector': 9,\n",
       " 'portray': 9,\n",
       " 'student': 9,\n",
       " 'highli': 9,\n",
       " 'boast': 9,\n",
       " 'murasaki': 9,\n",
       " 'fulli': 9,\n",
       " 'day': 9,\n",
       " 'throughout': 9,\n",
       " 'glori': 9,\n",
       " 'flask': 9,\n",
       " 'visual': 9,\n",
       " 'choli': 9,\n",
       " 'land': 9,\n",
       " 'characterist': 9,\n",
       " 'matchlock': 9,\n",
       " 'veget': 9,\n",
       " 'control': 9,\n",
       " 'templ': 9,\n",
       " 'expo': 9,\n",
       " 'effect': 9,\n",
       " 'wu': 9,\n",
       " 'name': 9,\n",
       " 'giri': 9,\n",
       " 'enter': 9,\n",
       " 'feather': 9,\n",
       " 'case': 9,\n",
       " 'hookah': 9,\n",
       " 'unknown': 9,\n",
       " 'princess': 9,\n",
       " 'shoup': 9,\n",
       " 'plume': 9,\n",
       " 'arhat': 9,\n",
       " 'curat': 9,\n",
       " 'employ': 9,\n",
       " 'histor': 9,\n",
       " 'punch': 9,\n",
       " 'twenti': 9,\n",
       " 'rich': 9,\n",
       " 'support': 9,\n",
       " 'pictur': 9,\n",
       " 'float': 9,\n",
       " 'stream': 9,\n",
       " 'honor': 9,\n",
       " 'later': 9,\n",
       " 'zedong': 9,\n",
       " 'katar': 9,\n",
       " 'floral': 9,\n",
       " 'fish': 9,\n",
       " 'encircl': 9,\n",
       " 'tray': 9,\n",
       " 'vine': 9,\n",
       " 'inspir': 9,\n",
       " 'charm': 9,\n",
       " 'button': 9,\n",
       " 'impli': 9,\n",
       " 'finger': 9,\n",
       " 'ram': 9,\n",
       " 'eleg': 9,\n",
       " 'u': 9,\n",
       " 'purana': 9,\n",
       " 'random': 9,\n",
       " 'fresco': 9,\n",
       " 'consid': 8,\n",
       " 'b': 8,\n",
       " 'worshipp': 8,\n",
       " 'hilt': 8,\n",
       " 'carpet': 8,\n",
       " 'boston': 8,\n",
       " 'diagon': 8,\n",
       " 'theme': 8,\n",
       " 'mother': 8,\n",
       " 'heavi': 8,\n",
       " 'high': 8,\n",
       " 'sometim': 8,\n",
       " 'ladi': 8,\n",
       " 'stem': 8,\n",
       " 'formal': 8,\n",
       " 'dhoti': 8,\n",
       " 'tile': 8,\n",
       " 'ride': 8,\n",
       " 'feng': 8,\n",
       " 'regist': 8,\n",
       " 'pencil': 8,\n",
       " 'father': 8,\n",
       " 'meet': 8,\n",
       " 'twelv': 8,\n",
       " 'best': 8,\n",
       " 'bridg': 8,\n",
       " 'american': 8,\n",
       " 'entranc': 8,\n",
       " 'rain': 8,\n",
       " 'chip': 8,\n",
       " 'path': 8,\n",
       " 'pull': 8,\n",
       " 'straight': 8,\n",
       " 'manner': 8,\n",
       " 'sunris': 8,\n",
       " 'possibl': 8,\n",
       " 'wave': 8,\n",
       " 'sparrow': 8,\n",
       " 'quarter': 8,\n",
       " 'size': 8,\n",
       " 'good': 8,\n",
       " 'cap': 8,\n",
       " 'floor': 8,\n",
       " 'buddhism': 8,\n",
       " 'said': 8,\n",
       " 'goddess': 8,\n",
       " 'class': 8,\n",
       " 'poetri': 8,\n",
       " 'sacr': 8,\n",
       " 'bank': 8,\n",
       " 'poet': 8,\n",
       " 'india': 8,\n",
       " 'malwa': 8,\n",
       " 'could': 8,\n",
       " 'brahma': 8,\n",
       " 'local': 8,\n",
       " 'metal': 8,\n",
       " 'field': 8,\n",
       " 'touch': 8,\n",
       " 'give': 8,\n",
       " 'forward': 8,\n",
       " 'examin': 8,\n",
       " 'air': 8,\n",
       " 'visit': 8,\n",
       " 'rukmini': 8,\n",
       " 'tiger': 8,\n",
       " 'america': 8,\n",
       " 'chaniya': 8,\n",
       " 'multipl': 8,\n",
       " 'attract': 8,\n",
       " 'provid': 8,\n",
       " 'toe': 8,\n",
       " 'lap': 8,\n",
       " 'dedic': 8,\n",
       " 'folio': 8,\n",
       " 'boar': 8,\n",
       " 'close': 8,\n",
       " 'make': 8,\n",
       " 'ii': 8,\n",
       " 'drum': 8,\n",
       " 'son': 8,\n",
       " 'canopi': 8,\n",
       " 'fleck': 8,\n",
       " 'join': 8,\n",
       " 'mingqiu': 8,\n",
       " 'correspond': 8,\n",
       " 'carv': 8,\n",
       " 'pendant': 8,\n",
       " 'spirit': 8,\n",
       " 'slight': 8,\n",
       " 'travel': 8,\n",
       " 'hunter': 8,\n",
       " 'creatur': 8,\n",
       " 'complex': 8,\n",
       " 'descript': 8,\n",
       " 'staff': 8,\n",
       " 'connoisseur': 8,\n",
       " 'xu': 7,\n",
       " 'walk': 7,\n",
       " 'societi': 7,\n",
       " 'kaoru': 7,\n",
       " 'gun': 7,\n",
       " 'apron': 7,\n",
       " 'boy': 7,\n",
       " 'particip': 7,\n",
       " 'book': 7,\n",
       " 'youth': 7,\n",
       " 'nandi': 7,\n",
       " 'saint': 7,\n",
       " 'summer': 7,\n",
       " 'regard': 7,\n",
       " 'dayb': 7,\n",
       " 'lost': 7,\n",
       " 'sinc': 7,\n",
       " 'sport': 7,\n",
       " 'bring': 7,\n",
       " 'sik': 7,\n",
       " 'jiqian': 7,\n",
       " 'slide': 7,\n",
       " 'rooster': 7,\n",
       " 'write': 7,\n",
       " 'acryl': 7,\n",
       " 'never': 7,\n",
       " 'loo': 7,\n",
       " 'integr': 7,\n",
       " 'fung': 7,\n",
       " 'cherri': 7,\n",
       " 'teacher': 7,\n",
       " 'chu': 7,\n",
       " 'represent': 7,\n",
       " 'prayer': 7,\n",
       " 'stretch': 7,\n",
       " 'often': 7,\n",
       " 'arch': 7,\n",
       " 'result': 7,\n",
       " 'ceremoni': 7,\n",
       " 'defin': 7,\n",
       " 'home': 7,\n",
       " 'mind': 7,\n",
       " 'bust': 7,\n",
       " 'shield': 7,\n",
       " 'gather': 7,\n",
       " 'garland': 7,\n",
       " 'jewel': 7,\n",
       " 'numer': 7,\n",
       " 'multi': 7,\n",
       " 'wet': 7,\n",
       " 'lie': 7,\n",
       " 'smaller': 7,\n",
       " 'upright': 7,\n",
       " 'beyond': 7,\n",
       " 'produc': 7,\n",
       " 'yu': 7,\n",
       " 'watch': 7,\n",
       " 'monkey': 7,\n",
       " 'contemporari': 7,\n",
       " 'awn': 7,\n",
       " 'coupl': 7,\n",
       " 'elderli': 7,\n",
       " 'perform': 7,\n",
       " 'stick': 7,\n",
       " 'stain': 7,\n",
       " 'frontal': 7,\n",
       " 'bent': 7,\n",
       " 'practic': 7,\n",
       " 'medallion': 7,\n",
       " 'convey': 7,\n",
       " 'bull': 7,\n",
       " 'florenc': 7,\n",
       " 'demon': 7,\n",
       " 'tsing': 7,\n",
       " 'knee': 7,\n",
       " 'grace': 7,\n",
       " 'kashmir': 7,\n",
       " 'den': 7,\n",
       " 'twentieth': 7,\n",
       " 'claim': 7,\n",
       " 'shanghai': 7,\n",
       " 'resembl': 7,\n",
       " 'block': 7,\n",
       " 'captur': 7,\n",
       " 'daughter': 7,\n",
       " 'mahabharata': 7,\n",
       " 'display': 7,\n",
       " 'low': 7,\n",
       " 'marwar': 7,\n",
       " 'divin': 7,\n",
       " 'lotus': 7,\n",
       " 'blind': 7,\n",
       " 'note': 6,\n",
       " 'european': 6,\n",
       " 'gain': 6,\n",
       " 'belt': 6,\n",
       " 'earlier': 6,\n",
       " 'divid': 6,\n",
       " 'crete': 6,\n",
       " 'rao': 6,\n",
       " 'hell': 6,\n",
       " 'circl': 6,\n",
       " 'everi': 6,\n",
       " 'depart': 6,\n",
       " 'studio': 6,\n",
       " 'bhagavata': 6,\n",
       " 'glove': 6,\n",
       " 'eman': 6,\n",
       " 'imperi': 6,\n",
       " 'final': 6,\n",
       " 'pose': 6,\n",
       " 'ray': 6,\n",
       " 'grape': 6,\n",
       " 'michizan': 6,\n",
       " 'shrinathji': 6,\n",
       " 'vignett': 6,\n",
       " 'fashion': 6,\n",
       " 'caparison': 6,\n",
       " 'tend': 6,\n",
       " 'northern': 6,\n",
       " 'death': 6,\n",
       " 'dragon': 6,\n",
       " 'clearli': 6,\n",
       " 'whose': 6,\n",
       " 'demonstr': 6,\n",
       " 'ho': 6,\n",
       " 'creation': 6,\n",
       " 'achiev': 6,\n",
       " 'dancer': 6,\n",
       " 'descend': 6,\n",
       " ...}"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this looks pretty good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset\n",
    "Now we will subset to descriptions that include the word \"abstract\"  \n",
    "Ideally, we would subset by existing keyword 'abstraction' but since this data doesn't contain such tagging system, we will just use inclusion of the word 'abstract' as a parameter to subset abstract art vs non-abstract art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_df = clean_df[(clean_df.description.apply(lambda x: 'abstract' in x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there are only 14 pieces that included the term 'abstract'. For now, we will go ahead with this data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
